{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CONVOLUTIONAL NEURAL NETWORK</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\lana\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\lana\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "c:\\users\\lana\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "c:\\users\\lana\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2835s 354ms/step - loss: 0.3422 - acc: 0.8402 - val_loss: 0.6551 - val_acc: 0.7924\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2869s 359ms/step - loss: 0.0943 - acc: 0.9649 - val_loss: 1.0194 - val_acc: 0.7842\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2780s 348ms/step - loss: 0.0481 - acc: 0.9830 - val_loss: 1.1641 - val_acc: 0.7940\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2514s 314ms/step - loss: 0.0357 - acc: 0.9875 - val_loss: 1.3529 - val_acc: 0.7975\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2504s 313ms/step - loss: 0.0286 - acc: 0.9903 - val_loss: 1.6859 - val_acc: 0.7660\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 30551s 4s/step - loss: 0.0241 - acc: 0.9921 - val_loss: 1.5768 - val_acc: 0.7810\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2262s 283ms/step - loss: 0.0210 - acc: 0.9930 - val_loss: 1.5593 - val_acc: 0.7821\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2281s 285ms/step - loss: 0.0182 - acc: 0.9941 - val_loss: 1.5967 - val_acc: 0.7865\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2624s 328ms/step - loss: 0.0177 - acc: 0.9944 - val_loss: 1.5687 - val_acc: 0.7963\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2316s 290ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 1.7255 - val_acc: 0.7798\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2812s 352ms/step - loss: 0.0139 - acc: 0.9955 - val_loss: 1.6453 - val_acc: 0.7889\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2486s 311ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 1.7225 - val_acc: 0.7819\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2424s 303ms/step - loss: 0.0126 - acc: 0.9959 - val_loss: 1.9986 - val_acc: 0.7690\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2340s 292ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 1.8981 - val_acc: 0.7676\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2675s 334ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 1.8415 - val_acc: 0.7760\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 4969s 621ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 1.7959 - val_acc: 0.7936\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2309s 289ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 1.9623 - val_acc: 0.7751\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 2302s 288ms/step - loss: 0.0108 - acc: 0.9969 - val_loss: 1.9719 - val_acc: 0.7798\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 2344s 293ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 1.9805 - val_acc: 0.7774\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2466s 308ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 1.8338 - val_acc: 0.7896\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2431s 304ms/step - loss: 0.0091 - acc: 0.9972 - val_loss: 1.9328 - val_acc: 0.7774\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 2258s 282ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 1.7665 - val_acc: 0.7966\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 5601s 700ms/step - loss: 0.0077 - acc: 0.9976 - val_loss: 1.8551 - val_acc: 0.7824\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2671s 334ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 1.8840 - val_acc: 0.7916\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2646s 331ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 1.9722 - val_acc: 0.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be370e3cf8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# create convolutional layer\n",
    "classifier.add(Conv2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu')) # 32 features map, 32 filters of 3x3, input shape = shape of image\n",
    "\n",
    "# pooling step -> reduce size of feature maps in order to reduce the number of nodes in fully conected layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flattening --> put into vector\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# fully connected layer\n",
    "classifier.add(Dense(output_dim=128, activation='relu'))\n",
    "classifier.add(Dense(output_dim=1, activation='sigmoid'))\n",
    "\n",
    "# compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# apply CNN to our dataset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('CatsDogs/training_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('CatsDogs/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                        steps_per_epoch=8000,\n",
    "                        epochs=25,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
